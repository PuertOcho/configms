server:
  port: ${PORT_INTENT_MANAGER:8082}

spring:
  application:
    name: ${INTENT_MANAGER_SERVICE:intent-manager}
  
  # Redis Configuration for Conversation State
  data:
    redis:
      host: ${REDIS_HOST:localhost}
      port: ${REDIS_PORT:6379}
      timeout: 2000ms
      lettuce:
        pool:
          max-active: 8
          max-idle: 8
          min-idle: 2
  
  # Jackson JSON Configuration
  jackson:
    default-property-inclusion: NON_NULL
    serialization:
      write-dates-as-timestamps: false
    deserialization:
      fail-on-unknown-properties: false

# Eureka Client Configuration
eureka:
  client:
    service-url:
      defaultZone: ${EUREKA_URL:http://eurekams:8761/eureka/}
    fetch-registry: true
    register-with-eureka: true
  instance:
    prefer-ip-address: true
    hostname: ${HOSTNAME:intent-manager}

# Configuration Files
config:
  files:
    intents: ${INTENTS_CONFIG_FILE:classpath:config/intents.json}
    mcp-registry: ${MCP_REGISTRY_FILE:classpath:config/mcp_registry.json}
    moe-voting: ${MOE_VOTING_FILE:classpath:config/moe_voting.json}
    hot-reload: ${CONFIG_HOT_RELOAD:true}

# MCP Integration Configuration
mcp:
  enabled: ${MCP_ENABLED:true}
  timeout: 30s
  retry-attempts: 3
  services:
    whisper:
      url: ${WHISPER_SERVICE_URL:http://whisper-ms:5000}
      enabled: ${WHISPER_ENABLED:true}
    weather:
      url: ${WEATHER_SERVICE_URL:http://weather-mcp:5000}
      enabled: ${WEATHER_ENABLED:true}
    taiga:
      url: ${TAIGA_SERVICE_URL:http://taiga-mcp-ms:5000}
      enabled: ${TAIGA_ENABLED:true}
    system:
      url: ${SYSTEM_SERVICE_URL:http://system-mcp:5000}
      enabled: ${SYSTEM_ENABLED:true}

# LLM Configuration
llm:
  primary:
    model: ${PRIMARY_LLM_MODEL:gpt-4}
    provider: ${PRIMARY_LLM_PROVIDER:openai}
    api-key: ${OPENAI_API_KEY:}
  timeout: ${LLM_TIMEOUT:30s}
  max-tokens: ${LLM_MAX_TOKENS:4096}
  temperature: ${LLM_TEMPERATURE:0.7}
  max-retries: ${LLM_MAX_RETRIES:3}

# Vector Store Configuration
vector-store:
  type: ${VECTOR_STORE_TYPE:in-memory}
  chroma:
    url: ${CHROMA_URL:http://localhost:8000}
  collection-name: ${VECTOR_STORE_COLLECTION:intent-examples}
  embedding-dimension: ${VECTOR_STORE_EMBEDDING_DIMENSION:1536}
  max-results: ${VECTOR_STORE_MAX_RESULTS:10}
  similarity-threshold: ${VECTOR_STORE_SIMILARITY_THRESHOLD:0.7}
  initialize-with-examples: ${VECTOR_STORE_INIT_EXAMPLES:true}
  example-count: ${VECTOR_STORE_EXAMPLE_COUNT:5}

# MoE Configuration
moe:
  enabled: ${MOE_ENABLED:true}
  consensus-threshold: 0.6
  max-debate-rounds: 1
  llm-a:
    model: ${MOE_LLM_A_MODEL:gpt-4}
  llm-b:
    model: ${MOE_LLM_B_MODEL:claude-3-sonnet-20240229}
  llm-c:
    model: ${MOE_LLM_C_MODEL:gpt-3.5-turbo}

# Conversation Management
conversation:
  session-ttl: ${SESSION_TTL:3600}  # 1 hour in seconds
  max-history-entries: ${MAX_HISTORY:50}
  auto-complete-threshold: ${AUTO_COMPLETE_THRESHOLD:0.85}
  subtask-timeout: ${SUBTASK_TIMEOUT:120}  # 2 minutes per subtask

# Logging Configuration
logging:
  level:
    com.intentmanagerms: ${LOG_LEVEL:INFO}
    dev.langchain4j: ${LANGCHAIN4J_LOG_LEVEL:WARN}
    org.springframework.data.redis: WARN
  pattern:
    console: "%d{yyyy-MM-dd HH:mm:ss} [%thread] %-5level [%logger{36}] - %msg%n"

# Management & Monitoring
management:
  endpoints:
    web:
      exposure:
        include: health,info,metrics,prometheus
  endpoint:
    health:
      show-details: when-authorized
  prometheus:
    metrics:
      export:
        enabled: true

# OpenAPI Documentation
springdoc:
  api-docs:
    path: /api-docs
  swagger-ui:
    path: /swagger-ui.html
    tags-sorter: alpha
    operations-sorter: alpha
  info:
    title: Intent Manager MS - LLM-RAG + MoE
    description: Intent classification and conversation management using LLM-RAG with Mixture of Experts voting system
    version: 2.0.0-LLM-RAG
    contact:
      name: PuertoCho Assistant Team